{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a710ff8c",
   "metadata": {},
   "source": [
    "<font size=3>**IMPORTID**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "88b5e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as HGBC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import winsound\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682f9b5f",
   "metadata": {},
   "source": [
    "<font size=3>**FUNKTSIOONID**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "4556a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotFeatures(dataframe, sub_rows):\n",
    "    cols = dataframe.columns\n",
    "\n",
    "    fig, axs = plt.subplots(sub_rows, 2, figsize=(20, 200))\n",
    "    for i in range(len(cols)-1):\n",
    "        values = dataframe[cols[i]].to_numpy()\n",
    "        df = pd.DataFrame({\"value\" : values, \"result\" : dataframe[\"compliance_2021\"]})\n",
    "        df = df.sort_values(by=\"value\")\n",
    "\n",
    "        for j in range(df[\"value\"].shape[0]):\n",
    "            if df[\"result\"].iloc[j] == 1:\n",
    "                axs[i//2, i%2].plot(j, df[\"value\"].iloc[j], \"go\")\n",
    "            else:\n",
    "                axs[i//2, i%2].plot(j, df[\"value\"].iloc[j], \"ro\", markersize=3)\n",
    "\n",
    "        axs[i//2, i%2].set_title(cols[i])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "f04cb7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(file):\n",
    "    df = pd.read_csv(file).drop(columns=[\"compliance_2019\", \"compliance_2020\", \n",
    "                                                      \"Enterococci_2019\", \"Enterococci_2020\", \"Escherichia-coli-Colilert_2019\",\n",
    "                                                     \"Escherichia-coli-Colilert_2020\", \"Escherichia-coli_2019\", \"Escherichia-coli_2020\"])\n",
    "\n",
    "    station_id = df[\"station_id\"]\n",
    "    df = df.drop(columns=\"station_id\")\n",
    "\n",
    "    cols = df.columns\n",
    "\n",
    "    limit = [60, 1.5, 1.5, 300, 10, 30, 350, 8, 40, 3000, 1.75, 2000, 400, 20, 0.15, 10, 5, 3, 300, 80, 4, 10, 20, 9]\n",
    "\n",
    "    for i in range(len(cols)-1):\n",
    "        col = np.array(df[cols[i]].values.tolist())\n",
    "        df[cols[i]] = np.where(col > limit[i//2], np.nan, col).tolist()\n",
    "\n",
    "    df = df.fillna(df.mean())\n",
    "    \n",
    "    return [df, station_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "e2d85aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning_2(file):\n",
    "    df = pd.read_csv(file).drop(columns=[\"Color-Pt-Co-unit_2019\", \"Color-Pt-Co-unit_2020\",\n",
    "                                        \"Enterococci_2019\", \"Enterococci_2020\", \"Escherichia-coli-Colilert_2019\",\n",
    "                                        \"Escherichia-coli-Colilert_2020\", \"Escherichia-coli_2019\", \"Escherichia-coli_2020\"])\n",
    "\n",
    "    station_id = df[\"station_id\"]\n",
    "    df = df.drop(columns=\"station_id\")\n",
    "\n",
    "    cols = df.columns\n",
    "\n",
    "    limit = [60, 1.5, 1.5, 300, 10, 30, 350, 40, 3000, 1.75, 2000, 400, 20, 0.15, 10, 5, 3, 300, 80, 4, 10, 20, 9]\n",
    "\n",
    "    for i in range(len(cols)-3):\n",
    "        col = np.array(df[cols[i]].values.tolist())\n",
    "        df[cols[i]] = np.where(col > limit[i//2], np.nan, col).tolist()\n",
    "    \n",
    "    return [df, station_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "1f251363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_balance(file):\n",
    "    df = pd.read_csv(file).drop(columns=[\"compliance_2019\", \"compliance_2020\", \n",
    "                                                      \"Enterococci_2019\", \"Enterococci_2020\", \"Escherichia-coli-Colilert_2019\",\n",
    "                                                     \"Escherichia-coli-Colilert_2020\", \"Escherichia-coli_2019\", \"Escherichia-coli_2020\"])\n",
    "\n",
    "    \n",
    "    positive_cases = df[df[\"compliance_2021\"] == 1]\n",
    "    negative_sample = df[df[\"compliance_2021\"] == 0].sample(132)\n",
    "    df_bal = pd.concat([positive_cases, negative_sample])\n",
    "    df_bal.sort_index(inplace=True)\n",
    "    \n",
    "    station_id = df_bal[\"station_id\"]\n",
    "    df_bal = df_bal.drop(columns=\"station_id\")\n",
    "\n",
    "    cols = df_bal.columns\n",
    "\n",
    "    limit = [60, 1.5, 1.5, 300, 10, 30, 350, 8, 40, 3000, 1.75, 2000, 400, 20, 0.15, 10, 5, 3, 300, 80, 4, 10, 20, 9]\n",
    "\n",
    "    for i in range(len(cols)-1):\n",
    "        col = np.array(df_bal[cols[i]].values.tolist())\n",
    "        df_bal[cols[i]] = np.where(col > limit[i//2], np.nan, col).tolist()\n",
    "\n",
    "    df_bal = df_bal.fillna(df_bal.mean())\n",
    "    \n",
    "    return [df_bal, station_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "1c8b5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_comp_21(dataframe, comp_19, comp_20):\n",
    "    \n",
    "    cols_21 = comp_19.columns\n",
    "    comp_21 = pd.DataFrame(columns=cols_21, index=np.arange(dataframe.shape[0]))\n",
    "    \n",
    "    dataframe = dataframe.drop(columns=[\"compliance_2019\", \"compliance_2020\"])\n",
    "    cols = dataframe.columns\n",
    "\n",
    "    for i in range(len(cols_21)-1):\n",
    "        for j in range(dataframe.shape[0]):\n",
    "            data_19 = dataframe[cols[i*2]].iloc[j]\n",
    "            data_20 = dataframe[cols[i*2+1]].iloc[j]\n",
    "\n",
    "            if dataframe[cols[i*2]].isnull()[j] and dataframe[cols[i*2+1]].isnull()[j]:\n",
    "                data_21 = np.nan\n",
    "            elif dataframe[cols[i*2]].isnull()[j]:\n",
    "                data_21 = data_20\n",
    "            elif dataframe[cols[i*2+1]].isnull()[j]:\n",
    "                data_21 = data_19\n",
    "            else:\n",
    "                dif = data_20 - data_19\n",
    "                data_21 = data_20 + dif\n",
    "\n",
    "                if data_21 < 0:\n",
    "                    data_21 = 0\n",
    "\n",
    "            col = cols_21[i]\n",
    "\n",
    "            comp_21.at[j, col] = data_21\n",
    "\n",
    "    try:\n",
    "        comp_21[\"compliance\"] = dataframe[\"compliance_2021\"]\n",
    "    except:\n",
    "        comp_21 = comp_21.drop(columns=\"compliance\")\n",
    "    \n",
    "    return comp_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "f68ebae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_years(dataframe):\n",
    "    \n",
    "    try:\n",
    "        dataframe = dataframe.drop(columns=\"compliance_2021\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    comp_19 = dataframe\n",
    "    comp_20 = dataframe\n",
    "\n",
    "    cols = dataframe.columns\n",
    "\n",
    "    for i in range((len(cols))//2):\n",
    "        comp_19 = comp_19.drop(columns = cols[i*2+1])\n",
    "        comp_20 = comp_20.drop(columns = cols[i*2])\n",
    "\n",
    "    cols_19 = comp_19.columns\n",
    "    cols_20 = comp_20.columns\n",
    "\n",
    "    for i in range((len(cols_19))):\n",
    "        comp_19 = comp_19.rename(columns={cols_19[i] : cols_19[i][:-5]})\n",
    "        comp_20 = comp_20.rename(columns={cols_20[i] : cols_20[i][:-5]})\n",
    "        \n",
    "    comp_19 = comp_19.drop(columns=[\"Coli-like-bacteria\", \"Boron\", \"Oxidability\", \"Electrical-conductivity\", \n",
    "                                        \"Colony-count-at-22-C\", \"Nitrite\", \"Taste-ball-units\", \"Sulphate\", \n",
    "                                       \"Aluminium\", \"Nitrate\", \"Fluoride\", \"Odour-dilution-level\", \"Turbidity-NTU\", \n",
    "                                       \"Chloride\", \"Color-Pt-Co-unit\", \"Smell-ball-units\"])\n",
    "    \n",
    "    comp_20 = comp_20.drop(columns=[\"Coli-like-bacteria\", \"Boron\", \"Oxidability\", \"Electrical-conductivity\", \n",
    "                                        \"Colony-count-at-22-C\", \"Nitrite\", \"Taste-ball-units\", \"Sulphate\", \n",
    "                                       \"Aluminium\", \"Nitrate\", \"Fluoride\", \"Odour-dilution-level\", \"Turbidity-NTU\", \n",
    "                                       \"Chloride\", \"Color-Pt-Co-unit\", \"Smell-ball-units\"])\n",
    "        \n",
    "    return [comp_19, comp_20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdf30d8",
   "metadata": {},
   "source": [
    "<font size=6>**1. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2067506",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7df6ded8",
   "metadata": {},
   "source": [
    "train_df = pd.read_csv(\"train.csv\").drop(columns=[\"station_id\", \"compliance_2019\", \"compliance_2020\"])\n",
    "train_df = train_df.fillna(train_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9ba444",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMETE KUJUTUS**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "093c6b7c",
   "metadata": {},
   "source": [
    "PlotFeatures(train_df, 27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f598d",
   "metadata": {},
   "source": [
    "<font size=3>**TRAIN SETS**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2b5c9c5",
   "metadata": {},
   "source": [
    "X_train = train_df.drop(columns=\"compliance_2021\")\n",
    "y_train = train_df[\"compliance_2021\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed1985",
   "metadata": {},
   "source": [
    "<font size=3>**PARIM RFC**<font> (runtime ~ 1 min) <br>\n",
    "<font size=1>RFC(max_depth = 18, min_samples_split = 2, min_samples_leaf = 4) <br>\n",
    "    acc = 84.5<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f38a9071",
   "metadata": {},
   "source": [
    "start = time()\n",
    "\n",
    "all_params = []\n",
    "all_acc = []\n",
    "\n",
    "for leaf in range(1,10,3):\n",
    "    for split in range(2,10,3):\n",
    "        for depth in range(8,20):\n",
    "            model = RFC(max_depth = depth, min_samples_split = split, min_samples_leaf = leaf)\n",
    "            params = model.get_params()\n",
    "\n",
    "            acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "            all_params.append(params)\n",
    "            all_acc.append(acc)\n",
    "                \n",
    "\n",
    "df_results = pd.DataFrame({\"params\" : all_params, \"acc\" : all_acc}).sort_values(by=\"acc\", ascending=False)\n",
    "\n",
    "print(\"Time: {} s\\n\".format(round(time()-start, 2)))\n",
    "print(\"Acc: {} %\\n\".format(round(df_results.iloc[0].acc, 4)*100))\n",
    "print(df_results.iloc[0].params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c6fb9",
   "metadata": {},
   "source": [
    "<font size=3>**TESTIMINE**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1fd1715c",
   "metadata": {},
   "source": [
    "test_df = pd.read_csv(\"test.csv\").drop(columns=[\"compliance_2019\", \"compliance_2020\"])\n",
    "test_df = test_df.fillna(train_df.mean())\n",
    "station_id = test_df[\"station_id\"]\n",
    "test_df = test_df.drop(columns=\"station_id\")\n",
    "\n",
    "\n",
    "model = RFC(max_depth = 15, min_samples_split = 2, min_samples_leaf = 4).fit(X_train, y_train)\n",
    "results = model.predict(test_df)\n",
    "results_df = pd.DataFrame({\"station_id\" : station_id, \"compliance_2021\" : results})\n",
    "results_df.to_csv(\"RFC_1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe06bee",
   "metadata": {},
   "source": [
    "<font size=6>**2. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea18b86",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30b92d81",
   "metadata": {},
   "source": [
    "train_df = data_cleaning(\"train.csv\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d424553",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMETE KUJUTUS**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8a96882",
   "metadata": {},
   "source": [
    "PlotFeatures(train_df, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6099d99e",
   "metadata": {},
   "source": [
    "<font size=3>**TRAIN SETS**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d48d542",
   "metadata": {},
   "source": [
    "X_train = train_df.drop(columns=\"compliance_2021\")\n",
    "y_train = train_df[\"compliance_2021\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ffab5a",
   "metadata": {},
   "source": [
    "<font size=3>**TESTIMINE**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3690327",
   "metadata": {},
   "source": [
    "test_df, station_id = data_cleaning(\"test.csv\")\n",
    "\n",
    "model = RFC(max_depth = 15, min_samples_split = 2, min_samples_leaf = 4).fit(X_train, y_train)\n",
    "results = model.predict(test_df)\n",
    "results_df = pd.DataFrame({\"station_id\" : station_id, \"compliance_2021\" : results})\n",
    "results_df.to_csv(\"RFC_cleaned_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036df60c",
   "metadata": {},
   "source": [
    "<font size=6>**3. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15c1644",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15ba615b",
   "metadata": {},
   "source": [
    "def data_cleaning_0(file):\n",
    "    df = pd.read_csv(file).drop(columns=[\"compliance_2019\", \"compliance_2020\", \n",
    "                                                      \"Enterococci_2019\", \"Enterococci_2020\", \"Escherichia-coli-Colilert_2019\",\n",
    "                                                     \"Escherichia-coli-Colilert_2020\", \"Escherichia-coli_2019\", \"Escherichia-coli_2020\"])\n",
    "\n",
    "    station_id = df[\"station_id\"]\n",
    "    df = df.drop(columns=\"station_id\")\n",
    "\n",
    "    cols = df.columns\n",
    "\n",
    "    limit = [60, 1.5, 1.5, 300, 10, 30, 350, 8, 40, 3000, 1.75, 2000, 400, 20, 0.15, 10, 5, 3, 300, 80, 4, 10, 20, 9]\n",
    "\n",
    "    for i in range(len(cols)-1):\n",
    "        col = np.array(df[cols[i]].values.tolist())\n",
    "        df[cols[i]] = np.where(col > limit[i//2], np.nan, col).tolist()\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    return [df, station_id]\n",
    "    \n",
    "train_df = data_cleaning(\"train.csv\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3400f6",
   "metadata": {},
   "source": [
    "<font size=3>**TRAIN SETS**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df23116c",
   "metadata": {},
   "source": [
    "X_train = train_df.drop(columns=\"compliance_2021\")\n",
    "y_train = train_df[\"compliance_2021\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f1533d",
   "metadata": {},
   "source": [
    "<font size=3>**TESTIMINE**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d529667",
   "metadata": {},
   "source": [
    "test_df, station_id = data_cleaning_0(\"test.csv\")\n",
    "\n",
    "model = RFC(max_depth = 15, min_samples_split = 2, min_samples_leaf = 4).fit(X_train, y_train)\n",
    "results = model.predict(test_df)\n",
    "results_df = pd.DataFrame({\"station_id\" : station_id, \"compliance_2021\" : results})\n",
    "results_df.to_csv(\"RFC_cleaned_data_0.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e02e21",
   "metadata": {},
   "source": [
    "<font size=6>**4. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994522f7",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6810307",
   "metadata": {},
   "source": [
    "train_df = data_cleaning(\"train.csv\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c771e",
   "metadata": {},
   "source": [
    "<font size=3>**TRAIN SETS**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33e95607",
   "metadata": {},
   "source": [
    "X_train = train_df.drop(columns=\"compliance_2021\")\n",
    "y_train = train_df[\"compliance_2021\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff228d06",
   "metadata": {},
   "source": [
    "<font size=3>**ERINEVAD MUDELID**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4343876",
   "metadata": {},
   "source": [
    "<font size=2>**RFC**<font> (runtime ~ 6.2 h) <br>\n",
    "<font size=1>RFC(criterion = \"gini\", n_estimators = 10, max_depth = 13, min_samples_split = 2, min_samples_leaf = 3) <br>\n",
    "    acc = 85.9<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "679329eb",
   "metadata": {},
   "source": [
    "start = time()\n",
    "\n",
    "all_params = []\n",
    "all_acc = []\n",
    "\n",
    "for leaf in range(1,10,2):\n",
    "    for split in range(2,10,2):\n",
    "        for depth in range(8,20):\n",
    "            for crit in [\"gini\", \"entropy\"]:\n",
    "                for n in range(10,401,10):\n",
    "                    model = RFC(criterion = crit, n_estimators = n, max_depth = depth, min_samples_split = split, min_samples_leaf = leaf)\n",
    "                    params = model.get_params()\n",
    "\n",
    "                    acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "                    all_params.append(params)\n",
    "                    all_acc.append(acc)\n",
    "                \n",
    "\n",
    "df_results = pd.DataFrame({\"params\" : all_params, \"acc\" : all_acc}).sort_values(by=\"acc\", ascending=False)\n",
    "\n",
    "print(\"Time: {} s\\n\".format(round(time()-start, 2)))\n",
    "print(\"Acc: {} %\\n\".format(round(df_results.iloc[0].acc, 4)*100))\n",
    "print(df_results.iloc[0].params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1495261",
   "metadata": {},
   "source": [
    "<font size=2>**KNN**<font>  (runtime ~ 8 min)<br>\n",
    "<font size=1>KNN(n_neighbors = 13, metric = \"euclidean\", leaf_size = 28) <br>\n",
    "    acc = 85.2<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4d967d1",
   "metadata": {},
   "source": [
    "start = time()\n",
    "\n",
    "all_params = []\n",
    "all_acc = []\n",
    "\n",
    "for leaf in range(10,101):\n",
    "    for nr in range(1,20):\n",
    "        for met in [\"cityblock\", \"cosine\", \"euclidean\"]:\n",
    "            model = KNN(n_neighbors = nr, metric = met, leaf_size = leaf)\n",
    "            params = model.get_params()\n",
    "            \n",
    "            acc = cross_val_score(model, X_train, y_train, cv = 5).mean()   \n",
    "            \n",
    "            all_params.append(params)\n",
    "            all_acc.append(acc)\n",
    "        \n",
    "df_results = pd.DataFrame({\"params\" : all_params, \"acc\" : all_acc}).sort_values(by=\"acc\", ascending=False)\n",
    "\n",
    "print(\"Time: {} s\\n\".format(round(time()-start, 2)))\n",
    "print(\"Acc: {} %\\n\".format(round(df_results.iloc[0].acc, 4)*100))\n",
    "print(df_results.iloc[0].params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ebbac7",
   "metadata": {},
   "source": [
    "<font size=2>**DTC**<font> (runtime ~ 46 s)<br>\n",
    "<font size=1>DTC(criterion = \"gini\", max_depth = 8, min_samples_split = 9, min_samples_leaf = 2) <br>\n",
    "    acc = 82.1<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abb64f4c",
   "metadata": {},
   "source": [
    "start = time()\n",
    "\n",
    "all_params = []\n",
    "all_acc = []\n",
    "\n",
    "for crit in [\"gini\", \"entropy\"]:\n",
    "    for leaf in range(1,10):\n",
    "        for split in range(2,10):\n",
    "            for depth in range(8,20):\n",
    "                model = DTC(criterion = crit, max_depth = depth, min_samples_split = split, min_samples_leaf = leaf)\n",
    "                params = model.get_params()\n",
    "                \n",
    "                acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "                   \n",
    "                all_params.append(params)\n",
    "                all_acc.append(acc)\n",
    "\n",
    "df_results = pd.DataFrame({\"params\" : all_params, \"acc\" : all_acc}).sort_values(by=\"acc\", ascending=False)\n",
    "\n",
    "print(\"Time: {} s\\n\".format(round(time()-start, 2)))\n",
    "print(\"Acc: {} %\\n\".format(round(df_results.iloc[0].acc, 4)*100))\n",
    "print(df_results.iloc[0].params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a1c74e",
   "metadata": {},
   "source": [
    "<font size=2>**SVC (auto)**<font> (runtime ~ 1 min) <br>\n",
    "<font size=1>acc = 73<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7eaeb21e",
   "metadata": {},
   "source": [
    "start = time()\n",
    "\n",
    "model = SVC(kernel = \"poly\", gamma = \"auto\")\n",
    "acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "print(\"Time: {} s\\n\".format(round(time()-start, 2)))\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661d430",
   "metadata": {},
   "source": [
    "<font size=2>**SVC (scale)**<font> (runtime ~ 1 s)<br>\n",
    "<font size=1>acc = 84.7<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ac62bdc",
   "metadata": {},
   "source": [
    "start = time()\n",
    "\n",
    "model = SVC(kernel = \"poly\", gamma = \"scale\")\n",
    "acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "print(\"Time: {} s\\n\".format(round(time()-start, 2)))\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0b38d",
   "metadata": {},
   "source": [
    "<font size=6>**5. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ca4b2f",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d26dbad",
   "metadata": {},
   "source": [
    "train_df = pd.read_csv(\"train.csv\").drop(columns=[\"station_id\", \"compliance_2019\", \"compliance_2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded09221",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMETE KUJUTUS**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79ffc39d",
   "metadata": {},
   "source": [
    "PlotFeatures(train_df, 27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0fe023",
   "metadata": {},
   "source": [
    "<font size=3>**TRAIN SETS**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d33aa54b",
   "metadata": {},
   "source": [
    "X_train = train_df.drop(columns=\"compliance_2021\")\n",
    "y_train = train_df[\"compliance_2021\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7bcf5d",
   "metadata": {},
   "source": [
    "<font size=2>**HGBC**<font> (runtime ~ 48 s) <br>\n",
    "<font size=1>HGBC(learning_rate = 0.01, max_iter = 100) <br>\n",
    "    acc = 85<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d98ec7ab",
   "metadata": {},
   "source": [
    "start = time()\n",
    "\n",
    "all_params = []\n",
    "all_acc = []\n",
    "\n",
    "for rate in [0.01, 0.05, 0.1]:\n",
    "    for iteration in range(100, 500, 100):\n",
    "        model = HGBC(learning_rate = rate, max_iter = iteration)\n",
    "        params = model.get_params()\n",
    "\n",
    "        acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "        all_params.append(params)\n",
    "        all_acc.append(acc)\n",
    "                \n",
    "\n",
    "df_results = pd.DataFrame({\"params\" : all_params, \"acc\" : all_acc}).sort_values(by=\"acc\", ascending=False)\n",
    "\n",
    "print(\"Time: {} s\\n\".format(round(time()-start, 2)))\n",
    "print(\"Acc: {} %\\n\".format(round(df_results.iloc[0].acc, 4)*100))\n",
    "print(df_results.iloc[0].params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfa354a",
   "metadata": {},
   "source": [
    "<font size=2>**HGBC**<font> (runtime ~ 10 s) <br>\n",
    "<font size=1>HGBC(learning_rate = 0.01, max_iter = 100, max_depth = 5) <br>\n",
    "    acc = 85.2<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "303b3afa",
   "metadata": {},
   "source": [
    "start = time()\n",
    "\n",
    "all_params = []\n",
    "all_acc = []\n",
    "\n",
    "for depth in range(1,10):\n",
    "    model = HGBC(learning_rate = 0.01, max_iter = 100, max_depth = depth)\n",
    "    params = model.get_params()\n",
    "\n",
    "    acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "    all_params.append(params)\n",
    "    all_acc.append(acc)\n",
    "                \n",
    "\n",
    "df_results = pd.DataFrame({\"params\" : all_params, \"acc\" : all_acc}).sort_values(by=\"acc\", ascending=False)\n",
    "\n",
    "print(\"Time: {} s\\n\".format(round(time()-start, 2)))\n",
    "print(\"Acc: {} %\\n\".format(round(df_results.iloc[0].acc, 4)*100))\n",
    "print(df_results.iloc[0].params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9b67a",
   "metadata": {},
   "source": [
    "<font size=3>**TESTIMINE**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d6165e2",
   "metadata": {},
   "source": [
    "test_df = pd.read_csv(\"test.csv\").drop(columns=[\"compliance_2019\", \"compliance_2020\"])\n",
    "station_id = test_df[\"station_id\"]\n",
    "test_df = test_df.drop(columns=\"station_id\")\n",
    "\n",
    "\n",
    "model = HGBC(learning_rate = 0.01, max_iter = 100, max_depth = 5).fit(X_train, y_train)\n",
    "results = model.predict(test_df)\n",
    "results_df = pd.DataFrame({\"station_id\" : station_id, \"compliance_2021\" : results})\n",
    "results_df.to_csv(\"HGBC_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e8c90",
   "metadata": {},
   "source": [
    "<font size=6>**6. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d241d4da",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e832bf9",
   "metadata": {},
   "source": [
    "def data_cleaning_nan_not_dropped(file):\n",
    "    df = pd.read_csv(file).drop(columns=[\"compliance_2019\", \"compliance_2020\", \n",
    "                                                      \"Enterococci_2019\", \"Enterococci_2020\", \"Escherichia-coli-Colilert_2019\",\n",
    "                                                     \"Escherichia-coli-Colilert_2020\", \"Escherichia-coli_2019\", \"Escherichia-coli_2020\"])\n",
    "\n",
    "    station_id = df[\"station_id\"]\n",
    "    df = df.drop(columns=\"station_id\")\n",
    "\n",
    "    cols = df.columns\n",
    "\n",
    "    limit = [60, 1.5, 1.5, 300, 10, 30, 350, 8, 40, 3000, 1.75, 2000, 400, 20, 0.15, 10, 5, 3, 300, 80, 4, 10, 20, 9]\n",
    "\n",
    "    for i in range(len(cols)-1):\n",
    "        col = np.array(df[cols[i]].values.tolist())\n",
    "        df[cols[i]] = np.where(col > limit[i//2], np.nan, col).tolist()\n",
    "    \n",
    "    return [df, station_id]\n",
    "    \n",
    "train_df = data_cleaning_nan_not_dropped(\"train.csv\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330a2edb",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMETE KUJUTUS**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c0041ec",
   "metadata": {},
   "source": [
    "PlotFeatures(train_df, 27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c70f0f4",
   "metadata": {},
   "source": [
    "<font size=3>**TRAIN SETS**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af5e00c7",
   "metadata": {},
   "source": [
    "X_train = train_df.drop(columns=\"compliance_2021\")\n",
    "y_train = train_df[\"compliance_2021\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5b596c",
   "metadata": {},
   "source": [
    "<font size=2>**HGBC**<font> (runtime ~ 7 s) <br>\n",
    "<font size=1>HGBC(learning_rate = 0.01) <br>\n",
    "    acc = 85<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b086fd4b",
   "metadata": {},
   "source": [
    "start = time()\n",
    "\n",
    "all_params = []\n",
    "all_acc = []\n",
    "\n",
    "for rate in [0.01, 0.02, 0.03, 0.5, 0.1]:\n",
    "    model = HGBC(learning_rate = rate)\n",
    "    params = model.get_params()\n",
    "\n",
    "    acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "    all_params.append(params)\n",
    "    all_acc.append(acc)\n",
    "                \n",
    "\n",
    "df_results = pd.DataFrame({\"params\" : all_params, \"acc\" : all_acc}).sort_values(by=\"acc\", ascending=False)\n",
    "\n",
    "print(\"Time: {} s\\n\".format(round(time()-start, 2)))\n",
    "print(\"Acc: {} %\\n\".format(round(df_results.iloc[0].acc, 4)*100))\n",
    "print(df_results.iloc[0].params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd280d",
   "metadata": {},
   "source": [
    "<font size=2>**HGBC**<font> (runtime ~ 32 s) <br>\n",
    "<font size=1>HGBC(learning_rate = 0.01, min_samples_leaf = 9) <br>\n",
    "    acc = 85.2<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7f392e0",
   "metadata": {},
   "source": [
    "start = time()\n",
    "\n",
    "all_params = []\n",
    "all_acc = []\n",
    "\n",
    "for leaf in range(1,10):\n",
    "    model = HGBC(learning_rate = 0.01, min_samples_leaf = leaf)\n",
    "    params = model.get_params()\n",
    "\n",
    "    acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "    all_params.append(params)\n",
    "    all_acc.append(acc)\n",
    "                \n",
    "\n",
    "df_results = pd.DataFrame({\"params\" : all_params, \"acc\" : all_acc}).sort_values(by=\"acc\", ascending=False)\n",
    "\n",
    "print(\"Time: {} s\\n\".format(round(time()-start, 2)))\n",
    "print(\"Acc: {} %\\n\".format(round(df_results.iloc[0].acc, 4)*100))\n",
    "print(df_results.iloc[0].params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ed350",
   "metadata": {},
   "source": [
    "<font size=3>**TESTIMINE**<font>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e6892a6",
   "metadata": {},
   "source": [
    "test_df, station_id = data_cleaning_nan_not_dropped(\"test.csv\")\n",
    "\n",
    "model = HGBC(learning_rate = 0.01, min_samples_leaf = 9).fit(X_train, y_train)\n",
    "results = model.predict(test_df)\n",
    "results_df = pd.DataFrame({\"station_id\" : station_id, \"compliance_2021\" : results})\n",
    "results_df.to_csv(\"HGBC_data_cleaning_nan_not_dropped.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5c22a",
   "metadata": {},
   "source": [
    "<font size=6>**7. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9a0df9",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "9a675f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_cleaning(\"train.csv\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0060068",
   "metadata": {},
   "source": [
    "<font size=3>**TRAIN SETS**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "70b08d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=\"compliance_2021\")\n",
    "y = train_df[\"compliance_2021\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded4e850",
   "metadata": {},
   "source": [
    "<font size=3>**RFC CONFUSION MATRIX**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "cdc74552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 0 10]\n",
      " [ 1 77]]\n"
     ]
    }
   ],
   "source": [
    "model = RFC(criterion = \"gini\", n_estimators = 10, max_depth = 13, \n",
    "            min_samples_split = 2, min_samples_leaf = 3).fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "print(\"Confusion matrix:\\n%s\" % matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9fe77",
   "metadata": {},
   "source": [
    "<font size=3>**KNN CONFUSION MATRIX**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "e17f80e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 0 10]\n",
      " [ 0 78]]\n"
     ]
    }
   ],
   "source": [
    "model = KNN(n_neighbors = 13, metric = \"euclidean\", leaf_size = 28).fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "print(\"Confusion matrix:\\n%s\" % matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd24ef",
   "metadata": {},
   "source": [
    "<font size=3>**SVC (auto) CONFUSION MATRIX**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "a1d42afe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [501]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSVC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpoly\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m      5\u001b[0m matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_val\u001b[38;5;241m.\u001b[39mvalues, pred, labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:251\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 251\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:333\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    319\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    323\u001b[0m (\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 333\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SVC(kernel = \"poly\", gamma = \"auto\").fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "print(\"Confusion matrix:\\n%s\" % matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0227c901",
   "metadata": {},
   "source": [
    "<font size=3>**SVC (scale) CONFUSION MATRIX**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48723e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel = \"poly\", gamma = \"scale\").fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "print(\"Confusion matrix:\\n%s\" % matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d23c47",
   "metadata": {},
   "source": [
    "<font size=3>**HGBC CONFUSION MATRIX**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09897d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HGBC(learning_rate = 0.01, max_iter = 100, max_depth = 5).fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "print(\"Confusion matrix:\\n%s\" % matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a422695",
   "metadata": {},
   "source": [
    "<font size=6>**8. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fff777",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbaa737",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_balance(\"train.csv\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aab8cc0",
   "metadata": {},
   "source": [
    "<font size=3>**TRAIN SETS**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c0af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=\"compliance_2021\")\n",
    "y = train_df[\"compliance_2021\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dd4f12",
   "metadata": {},
   "source": [
    "<font size=3>**RFC CONFUSION MATRIX**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a134a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RFC(criterion = \"gini\", n_estimators = 10, max_depth = 13, \n",
    "            min_samples_split = 2, min_samples_leaf = 3).fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "print(\"Confusion matrix:\\n%s\" % matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601e1386",
   "metadata": {},
   "source": [
    "<font size=3>**KNN CONFUSION MATRIX**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e3a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNN(n_neighbors = 13, metric = \"euclidean\", leaf_size = 28).fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "print(\"Confusion matrix:\\n%s\" % matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b89f1a",
   "metadata": {},
   "source": [
    "<font size=3>**SVC (auto) CONFUSION MATRIX**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c9bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel = \"poly\", gamma = \"auto\").fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "print(\"Confusion matrix:\\n%s\" % matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c5a1d",
   "metadata": {},
   "source": [
    "<font size=3>**SVC (scale) CONFUSION MATRIX**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e059b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel = \"poly\", gamma = \"scale\").fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "print(\"Confusion matrix:\\n%s\" % matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba5969c",
   "metadata": {},
   "source": [
    "<font size=3>**HGBC CONFUSION MATRIX**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b766f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HGBC(learning_rate = 0.01, max_iter = 100, max_depth = 5).fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "print(\"Confusion matrix:\\n%s\" % matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62fd52c",
   "metadata": {},
   "source": [
    "<font size=6>**9. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15558b01",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc18a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_balance(\"train.csv\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6765aabb",
   "metadata": {},
   "source": [
    "<font size=3>**TRAIN SETS**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05615afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=\"compliance_2021\")\n",
    "y = train_df[\"compliance_2021\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cca751",
   "metadata": {},
   "source": [
    "<font size=3>**RFC PROBABILITY**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c9050",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RFC(criterion = \"gini\", n_estimators = 10, max_depth = 13, \n",
    "            min_samples_split = 2, min_samples_leaf = 3).fit(X_train, y_train)\n",
    "\n",
    "pred = pd.DataFrame(model.predict_proba(X_val))[1]\n",
    "\n",
    "results = pd.DataFrame({\"pred\" : pred, \"true\" : y_val.reset_index(drop=True)})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d3f95",
   "metadata": {},
   "source": [
    "<font size=6>**10. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c9b321",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d28649",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_cleaning_2(\"train.csv\")[0]\n",
    "train_df = train_df.drop(columns=\"compliance_2021\")\n",
    "\n",
    "comp_19 = train_df\n",
    "comp_20 = train_df\n",
    "\n",
    "cols = train_df.columns\n",
    "\n",
    "for i in range((len(cols))//2):\n",
    "    comp_19 = comp_19.drop(columns = cols[i*2+1])\n",
    "    comp_20 = comp_20.drop(columns = cols[i*2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8bf7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = comp_19.corr()\n",
    "cols = comp_19.columns\n",
    "\n",
    "for col in cols:\n",
    "    for i in range(23):\n",
    "        element = cor[col].iloc[i]\n",
    "        if element != 1.0 and element > 0.55:\n",
    "            print(\"({}) - ({})   cor: {}\".format(col, cols[i], element))\n",
    "            \n",
    "cor = comp_20.corr()\n",
    "cols = comp_20.columns\n",
    "\n",
    "for col in cols:\n",
    "    for i in range(23):\n",
    "        element = cor[col].iloc[i]\n",
    "        if element != 1.0 and element > 0.55:\n",
    "            print(\"({}) - ({})   cor: {}\".format(col, cols[i], element))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda4eccc",
   "metadata": {},
   "source": [
    "<font size=6>**11. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81830044",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_cleaning_2(\"train.csv\")[0]\n",
    "train_df = train_df.drop(columns=\"compliance_2021\")\n",
    "\n",
    "comp_19 = train_df\n",
    "comp_20 = train_df\n",
    "\n",
    "cols = train_df.columns\n",
    "\n",
    "for i in range((len(cols))//2):\n",
    "    comp_19 = comp_19.drop(columns = cols[i*2+1])\n",
    "    comp_20 = comp_20.drop(columns = cols[i*2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672f6942",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_19 = comp_19.columns\n",
    "cols_20 = comp_20.columns\n",
    "\n",
    "for i in range((len(cols_19))):\n",
    "    comp_19 = comp_19.rename(columns={cols_19[i] : cols_19[i][:-5]})\n",
    "    comp_20 = comp_20.rename(columns={cols_20[i] : cols_20[i][:-5]})\n",
    "    \n",
    "train_df = pd.concat([comp_19, comp_20], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517e4178",
   "metadata": {},
   "source": [
    "<font size=3>**TRAIN SETS**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f60620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=\"compliance\")\n",
    "y = train_df[\"compliance\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df60841b",
   "metadata": {},
   "source": [
    "<font size=3>**RFC CONFUSION MATRIX**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a9bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RFC(criterion = \"gini\", n_estimators = 10, max_depth = 13, \n",
    "            min_samples_split = 2, min_samples_leaf = 3).fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "print(\"Confusion matrix:\\n%s\" % matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6328dcec",
   "metadata": {},
   "source": [
    "<font size=6>**12. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdf8a72",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4f990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_cleaning_2(\"train.csv\")[0]\n",
    "\n",
    "comp_19, comp_20 = sep_years(train_df.drop(columns=\"compliance_2021\"))\n",
    "comp_21 = gen_comp_21(train_df, comp_19, comp_20)\n",
    "\n",
    "train_df = comp_21\n",
    "\n",
    "train_df = train_df.fillna(train_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7bf666",
   "metadata": {},
   "source": [
    "<font size=3>**TRAIN SETS**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740ae82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cases = train_df[train_df[\"compliance\"] == 1]\n",
    "negative_sample = train_df[train_df[\"compliance\"] == 0].sample(positive_cases.shape[0])\n",
    "train_df = pd.concat([positive_cases, negative_sample], ignore_index=True)\n",
    "\n",
    "X = train_df.drop(columns=\"compliance\")\n",
    "y = train_df[\"compliance\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db68ce",
   "metadata": {},
   "source": [
    "<font size=3>**RFC CONFUSION MATRIX**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9ad890",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RFC(criterion = \"gini\", n_estimators = 10, max_depth = 13, \n",
    "            min_samples_split = 2, min_samples_leaf = 3).fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "print(\"Confusion matrix:\\n%s\" % matrix)\n",
    "\n",
    "model = RFC(criterion = \"gini\", n_estimators = 10, max_depth = 13, \n",
    "            min_samples_split = 2, min_samples_leaf = 3)\n",
    "\n",
    "acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "print(\"\\nacc:\", round(acc*100, 2) , \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a9f28",
   "metadata": {},
   "source": [
    "<font size=3>**TESTING**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eb0770",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=\"compliance\")\n",
    "y_train = train_df[\"compliance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ce74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df, station_id = data_cleaning_2(\"test.csv\")\n",
    "\n",
    "comp_19, comp_20 = sep_years(test_df)\n",
    "comp_21 = gen_comp_21(test_df, comp_19, comp_20)\n",
    "\n",
    "test_df = comp_21\n",
    "\n",
    "test_df = test_df.fillna(test_df.mean())\n",
    "\n",
    "model = RFC(max_depth = 15, min_samples_split = 2, min_samples_leaf = 4).fit(X_train, y_train)\n",
    "results = model.predict(test_df)\n",
    "results_df = pd.DataFrame({\"station_id\" : station_id, \"compliance_2021\" : results})\n",
    "results_df.to_csv(\"RFC_comp_21.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae1533",
   "metadata": {},
   "source": [
    "<font size=6>**12. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff7e70",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacfaa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_cleaning_2(\"train.csv\")[0]\n",
    "test_df = data_cleaning_2(\"test.csv\")[0]\n",
    "\n",
    "train_19, train_20 = sep_years(train_df)\n",
    "test_19, test_20 = sep_years(test_df)\n",
    "\n",
    "train_df = pd.concat([train_19, train_20, test_19, test_20], ignore_index=True)\n",
    "\n",
    "train_df = train_df.fillna(train_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d016d",
   "metadata": {},
   "source": [
    "<font size=3>**TRAIN SETS**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=\"compliance\")\n",
    "y_train = train_df[\"compliance\"]\n",
    "\n",
    "X_val = test_df.drop(columns=\"compliance\")\n",
    "y_val = test_df[\"compliance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dbebe8",
   "metadata": {},
   "source": [
    "<font size=3>**TESTING**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528bb78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RFC(criterion = \"gini\", n_estimators = 10, max_depth = 13, \n",
    "            min_samples_split = 2, min_samples_leaf = 3).fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "\n",
    "print(\"Positive guess acc:\", round(matrix[0][0]/(matrix[1][0] + matrix[0][0])*100, 2) , \"%\")\n",
    "print(\"Negative guess acc:\", round(matrix[1][1]/(matrix[1][1] + matrix[0][1])*100, 2) , \"%\")\n",
    "\n",
    "print(\"\\nPositive case find acc:\", round(matrix[0][0]/(matrix[0][1] + matrix[0][0])*100, 2) , \"%\")\n",
    "print(\"Negative case find acc:\", round(matrix[1][1]/(matrix[1][1] + matrix[1][0])*100, 2) , \"%\")\n",
    "\n",
    "model = RFC(criterion = \"gini\", n_estimators = 10, max_depth = 13, \n",
    "            min_samples_split = 2, min_samples_leaf = 3)\n",
    "\n",
    "acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "print(\"\\nacc:\", round(acc*100, 2) , \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f3a614",
   "metadata": {},
   "source": [
    "<font size=6>**13. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb000fa1",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14277af",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for i in range(100):\n",
    "    train_df = data_cleaning_2(\"train.csv\")[0]\n",
    "\n",
    "    comp_19, comp_20 = sep_years(train_df.drop(columns=\"compliance_2021\"))\n",
    "    comp_21 = gen_comp_21(train_df, comp_19, comp_20)\n",
    "\n",
    "    train_df = comp_21\n",
    "\n",
    "    train_df = train_df.fillna(train_df.mean())\n",
    "    train_df = train_df.sample(frac = 1, ignore_index=True)\n",
    "\n",
    "    train_df, test_df = [train_df.iloc[:352], train_df.iloc[352:]]\n",
    "    \n",
    "    \n",
    "    positive_cases = train_df[train_df[\"compliance\"] == 1]\n",
    "    negative_sample = train_df[train_df[\"compliance\"] == 0].sample(int(positive_cases.shape[0]*4.5))\n",
    "    df = pd.concat([positive_cases, negative_sample], ignore_index=True)\n",
    "\n",
    "    X_train = df.drop(columns=\"compliance\")\n",
    "    y_train = df[\"compliance\"]\n",
    "    X_val = test_df.drop(columns=\"compliance\")\n",
    "    y_val = test_df[\"compliance\"]\n",
    "    \n",
    "    model = RFC().fit(X_train, y_train)\n",
    "    pred = model.predict(X_val)\n",
    "    matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "    \n",
    "    if (matrix[0][0] + matrix[1][0]) != 0:\n",
    "        result.append(matrix[0][0]/(matrix[0][0] + matrix[1][0]))\n",
    "    \n",
    "print(round(sum(result) / len(result)*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84efe140",
   "metadata": {},
   "source": [
    "<font size=6>**14. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bf7c4f",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe8ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(file):\n",
    "    \n",
    "    try:\n",
    "        dataframe = pd.read_csv(file).drop(columns=[\"station_id\", \"compliance_2021\"])\n",
    "    except:\n",
    "        dataframe = pd.read_csv(file).drop(columns=\"station_id\")\n",
    "\n",
    "    comp_19, comp_20 = sep_years(dataframe)\n",
    "    dataframe = pd.concat([comp_19, comp_20], ignore_index=True)\n",
    "    \n",
    "    dataframe = dataframe.fillna(dataframe.mean())\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data(\"train.csv\")\n",
    "test_df = data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c152dd5",
   "metadata": {},
   "source": [
    "<font size=3>**TRAIN SETS**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=\"compliance\")\n",
    "y_train = train_df[\"compliance\"]\n",
    "\n",
    "X_val = test_df.drop(columns=\"compliance\")\n",
    "y_val = test_df[\"compliance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e96c5",
   "metadata": {},
   "source": [
    "<font size=3>**TESTING**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728514bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = []\n",
    "fa = []\n",
    "accs = []\n",
    "\n",
    "for i in range(10):\n",
    "    model = RFC().fit(X_train, y_train)\n",
    "    pred = model.predict(X_val)\n",
    "    matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "\n",
    "    model = RFC()\n",
    "    acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "    ga.append(matrix[0][0]/(matrix[1][0] + matrix[0][0]))\n",
    "    fa.append(matrix[0][0]/(matrix[0][1] + matrix[0][0]))\n",
    "    accs.append(acc)\n",
    "\n",
    "print(\"Guess acc:\", round(sum(ga)/len(ga)*100, 2) , \"%\")\n",
    "print(\"Find acc:\", round(sum(fa)/len(fa)*100, 2) , \"%\")\n",
    "print(\"acc:\", round(sum(accs)/len(accs)*100, 2) , \"%\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "cols = X_train.columns\n",
    "\n",
    "for col in cols:\n",
    "    X_train = train_df.drop(columns=[\"compliance\", col])\n",
    "    y_train = train_df[\"compliance\"]\n",
    "\n",
    "    X_val = test_df.drop(columns=[\"compliance\", col])\n",
    "    y_val = test_df[\"compliance\"]\n",
    "    \n",
    "    ga = []\n",
    "    fa = []\n",
    "    accs = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        model = RFC().fit(X_train, y_train)\n",
    "        pred = model.predict(X_val)\n",
    "        matrix = confusion_matrix(y_val.values, pred, labels=[1,0])\n",
    "\n",
    "        model = RFC()\n",
    "        acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "        \n",
    "        ga.append(matrix[0][0]/(matrix[1][0] + matrix[0][0]))\n",
    "        fa.append(matrix[0][0]/(matrix[0][1] + matrix[0][0]))\n",
    "        accs.append(acc)\n",
    "\n",
    "    print(col)\n",
    "    print(\"Guess acc:\", round(sum(ga)/len(ga)*100, 2) , \"%\")\n",
    "    print(\"Find acc:\", round(sum(fa)/len(fa)*100, 2) , \"%\")\n",
    "    print(\"acc:\", round(sum(accs)/len(accs)*100, 2) , \"%\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c524bb",
   "metadata": {},
   "source": [
    "<font size=6>**15. KATSE**<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48656be2",
   "metadata": {},
   "source": [
    "<font size=3>**ANDMED**<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "9d93544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_2(file):\n",
    "    dataframe = pd.read_csv(file).drop(columns=\"station_id\")\n",
    "\n",
    "    dataframe = dataframe.drop(columns=[\"compliance_2019\", \"Coli-like-bacteria_2019\", \"Boron_2019\", \"Oxidability_2019\", \"Electrical-conductivity_2019\", \n",
    "                                        \"Colony-count-at-22-C_2019\", \"Nitrite_2019\", \"Taste-ball-units_2019\", \"Sulphate_2019\", \n",
    "                                       \"Aluminium_2019\", \"Nitrate_2019\", \"Fluoride_2019\", \"Odour-dilution-level_2019\", \"Turbidity-NTU_2019\", \n",
    "                                       \"Chloride_2019\", \"Color-Pt-Co-unit_2019\", \"Smell-ball-units_2019\"])\n",
    "    \n",
    "    dataframe = dataframe.drop(columns=[\"compliance_2020\", \"Coli-like-bacteria_2020\", \"Boron_2020\", \"Oxidability_2020\", \"Electrical-conductivity_2020\", \n",
    "                                        \"Colony-count-at-22-C_2020\", \"Nitrite_2020\", \"Taste-ball-units_2020\", \"Sulphate_2020\", \n",
    "                                       \"Aluminium_2020\", \"Nitrate_2020\", \"Fluoride_2020\", \"Odour-dilution-level_2020\", \"Turbidity-NTU_2020\", \n",
    "                                       \"Chloride_2020\", \"Color-Pt-Co-unit_2020\", \"Smell-ball-units_2020\"])\n",
    "    \n",
    "    dataframe = dataframe.fillna(dataframe.mean())\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "3369a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_2(\"train.csv\")\n",
    "X_train = train_df.drop(columns=\"compliance_2021\")\n",
    "y_train = train_df[\"compliance_2021\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "f1d90b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 84.27 %\n",
      "\n",
      "\n",
      "Ammonium_2019\n",
      "acc: 84.89 %\n",
      "\n",
      "\n",
      "Ammonium_2020\n",
      "acc: 84.52 %\n",
      "\n",
      "\n",
      "Coli-like-bacteria-Colilert_2019\n",
      "acc: 84.66 %\n",
      "\n",
      "\n",
      "Coli-like-bacteria-Colilert_2020\n",
      "acc: 84.32 %\n",
      "\n",
      "\n",
      "Color-Pt/Co-scale_2019\n",
      "acc: 84.36 %\n",
      "\n",
      "\n",
      "Color-Pt/Co-scale_2020\n",
      "acc: 84.68 %\n",
      "\n",
      "\n",
      "Enterococci_2019\n",
      "acc: 84.75 %\n",
      "\n",
      "\n",
      "Enterococci_2020\n",
      "acc: 84.43 %\n",
      "\n",
      "\n",
      "Escherichia-coli-Colilert_2019\n",
      "acc: 84.61 %\n",
      "\n",
      "\n",
      "Escherichia-coli-Colilert_2020\n",
      "acc: 84.7 %\n",
      "\n",
      "\n",
      "Escherichia-coli_2019\n",
      "acc: 84.66 %\n",
      "\n",
      "\n",
      "Escherichia-coli_2020\n",
      "acc: 84.59 %\n",
      "\n",
      "\n",
      "Iron_2019\n",
      "acc: 84.59 %\n",
      "\n",
      "\n",
      "Iron_2020\n",
      "acc: 84.3 %\n",
      "\n",
      "\n",
      "Manganese_2019\n",
      "acc: 84.77 %\n",
      "\n",
      "\n",
      "Manganese_2020\n",
      "acc: 85.0 %\n",
      "\n",
      "\n",
      "Sodium_2019\n",
      "acc: 84.98 %\n",
      "\n",
      "\n",
      "Sodium_2020\n",
      "acc: 84.73 %\n",
      "\n",
      "\n",
      "Taste-dilution-degree_2019\n",
      "acc: 84.66 %\n",
      "\n",
      "\n",
      "Taste-dilution-degree_2020\n",
      "acc: 84.75 %\n",
      "\n",
      "\n",
      "pH _2019\n",
      "acc: 84.57 %\n",
      "\n",
      "\n",
      "pH _2020\n",
      "acc: 84.39 %\n",
      "\n",
      "\n",
      "compliance_2019\n",
      "acc: 84.75 %\n",
      "\n",
      "\n",
      "compliance_2020\n",
      "acc: 84.5 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "\n",
    "for i in range(10):\n",
    "    model = RFC()\n",
    "    acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "    accs.append(acc)\n",
    "\n",
    "print(\"acc:\", round(sum(accs)/len(accs)*100, 2) , \"%\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "cols = X_train.columns\n",
    "\n",
    "for col in cols:\n",
    "    X_train = train_df.drop(columns=[\"compliance_2021\", col])\n",
    "    y_train = train_df[\"compliance_2021\"]\n",
    "    \n",
    "    accs = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        model = RFC()\n",
    "        acc = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "        accs.append(acc)\n",
    "\n",
    "    print(col)\n",
    "    print(\"acc:\", round(sum(accs)/len(accs)*100, 2) , \"%\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
